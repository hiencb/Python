{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "%matplotlib inline\n",
    "\n",
    "sess = tf.Session()\n",
    "data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-04-18 18:30:48--  http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
      "Resolving archive.ics.uci.edu... 128.195.10.249\n",
      "Connecting to archive.ics.uci.edu|128.195.10.249|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 203415 (199K) [application/zip]\n",
      "Saving to: ‘SpamCollection.zip’\n",
      "\n",
      "SpamCollection.zip  100%[===================>] 198.65K   256KB/s    in 0.8s    \n",
      "\n",
      "2017-04-18 18:30:50 (256 KB/s) - ‘SpamCollection.zip’ saved [203415/203415]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget {data_url} -O SpamCollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  SpamCollection.zip\r\n",
      "  inflating: SpamCollection/SMSSpamCollection  \r\n",
      "  inflating: SpamCollection/readme   \r\n"
     ]
    }
   ],
   "source": [
    "!unzip -o SpamCollection.zip -d SpamCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                            Content\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamDf = pd.read_table('SpamCollection/SMSSpamCollection', header=None, names=['Class', 'Content'])\n",
    "nSamples = spamDf.shape[0]\n",
    "print(spamDf.shape)\n",
    "spamDf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spamDf['Label'] = spamDf['Class'].map(lambda c: 0 if c == 'ham' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting text length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spamDf['Text Length'] = spamDf['Content'].map(lambda txt: len(txt.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeText(text):\n",
    "    # Remove punctuation and digit\n",
    "    charFiltered = ''.join(c for c in text if c not in string.punctuation and c not in string.digits)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    spaceFiltered = ' '.join(w for w in charFiltered.split())\n",
    "    return spaceFiltered.lower()\n",
    "\n",
    "spamDf['Content'] = spamDf['Content'].map(normalizeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                            Content  Label  Text Length\n",
       "0   ham  go until jurong point crazy available only in ...      0           20\n",
       "1   ham                            ok lar joking wif u oni      0            6\n",
       "2  spam  free entry in a wkly comp to win fa cup final ...      1           28\n",
       "3   ham        u dun say so early hor u c already then say      0           11\n",
       "4   ham  nah i dont think he goes to usf he lives aroun...      0           13"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11843a978>]], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEFCAYAAADt1CyEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1184c3588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spamDf.hist('Text Length', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Identifying Embedding Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2739"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SENT_SIZE = 35\n",
    "MIN_WORD_FREQ = 3\n",
    "\n",
    "vocabProcessor = learn.preprocessing.VocabularyProcessor(max_document_length=MAX_SENT_SIZE, min_frequency=MIN_WORD_FREQ)\n",
    "wordIdx = vocabProcessor.fit_transform(spamDf['Content'])\n",
    "embeddingSize = len(vocabProcessor.vocabulary_._mapping)\n",
    "print(type(wordIdx))\n",
    "embeddingSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**TEST**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabProcessor.fit_transform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vocabProcessor.vocabulary_._mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "2739\n"
     ]
    }
   ],
   "source": [
    "print(type(vocab))\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortedVocab = sorted(vocab.items(), key=lambda i: i[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yuo', 2738),\n",
       " ('yogasana', 2737),\n",
       " ('yer', 2736),\n",
       " ('wow', 2735),\n",
       " (\"wouldn't\", 2734),\n",
       " ('wonders', 2733),\n",
       " ('wishing', 2732),\n",
       " ('wins', 2731),\n",
       " ('white', 2730),\n",
       " (\"where's\", 2729)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedVocab[: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 26, 305, 158,  32, 415,   0,  26, 288, 152,  62, 158,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1155,    3,  109,  106,   83,  508,    1, 1229,   83, 2591,  219,\n",
       "         105,  536,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0])]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "list(itertools.islice(wordIdx, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 4)\n",
      "(1115, 4)\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(nSamples)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "nTrains = int(nSamples * 0.8)\n",
    "trainIdx = idx[: nTrains]\n",
    "testIdx = idx[nTrains :]\n",
    "\n",
    "trainData = spamDf.iloc[trainIdx]\n",
    "testData = spamDf.iloc[testIdx]\n",
    "\n",
    "print(trainData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_2:0' shape=(2739, 2739) dtype=float32>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingMx = tf.convert_to_tensor(np.eye(embeddingSize, dtype=np.float32))\n",
    "embeddingMx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring Parameters and Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"W_3/read:0\", shape=(2739, 1), dtype=float32)\n",
      "Tensor(\"b_3/read:0\", shape=(1, 1), dtype=float32)\n",
      "Tensor(\"X_3:0\", shape=(35,), dtype=int32)\n",
      "Tensor(\"y_2:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.truncated_normal(shape=[embeddingSize, 1]), name='W')\n",
    "b = tf.Variable(tf.zeros(shape=[1, 1]), name='b')\n",
    "print(W)\n",
    "print(b)\n",
    "\n",
    "X = tf.placeholder(shape=[MAX_SENT_SIZE], dtype=tf.int32, name='X')\n",
    "y = tf.placeholder(shape=[1, 1], dtype=tf.float32, name='y')\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Indices of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X_embed_2:0\", shape=(35, 2739), dtype=float32)\n",
      "Tensor(\"X_sums_2:0\", shape=(2739,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X_embed = tf.nn.embedding_lookup(embeddingMx, X, name='X_embed')\n",
    "X_sums = tf.reduce_sum(X_embed, 0, name='X_sums')\n",
    "\n",
    "print(X_embed)\n",
    "print(X_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Outputs and Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X_sums_2D_4:0\", shape=(1, 2739), dtype=float32)\n",
      "Tensor(\"output_4:0\", shape=(1, 1), dtype=float32)\n",
      "Tensor(\"prediction_3:0\", shape=(1, 1), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X_sums_2D = tf.expand_dims(X_sums, 0, name='X_sums_2D')\n",
    "output = tf.add(tf.matmul(X_sums_2D, W), b, name='output')\n",
    "print(X_sums_2D)\n",
    "print(output)\n",
    "\n",
    "prediction = tf.sigmoid(output, name='prediction')\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=output, name='loss'))\n",
    "print(prediction)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"train\"\n",
      "op: \"NoOp\"\n",
      "input: \"^train/update_W_3/ApplyGradientDescent\"\n",
      "input: \"^train/update_b_3/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "train = optimizer.minimize(loss, name='train')\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#199 - loss: 4.766218662261963\n",
      "#399 - loss: 0.0009768157033249736\n",
      "#599 - loss: 0.057059064507484436\n",
      "#799 - loss: 0.002928269561380148\n",
      "#999 - loss: 0.00430036848410964\n",
      "#1199 - loss: 0.0007185084978118539\n",
      "#1399 - loss: 0.005021714139729738\n",
      "#1599 - loss: 2.275639295578003\n",
      "#1799 - loss: 0.02023402787744999\n",
      "#1999 - loss: 1.3315320014953613\n",
      "#2199 - loss: 0.001762574422173202\n",
      "#2399 - loss: 0.005373667925596237\n",
      "#2599 - loss: 4.365481800050475e-05\n",
      "#2799 - loss: 0.013578264974057674\n",
      "#2999 - loss: 0.011156373657286167\n",
      "#3199 - loss: 0.004315444268286228\n",
      "#3399 - loss: 0.6694560050964355\n",
      "#3599 - loss: 0.01589074730873108\n",
      "#3799 - loss: 0.05850490555167198\n",
      "#3999 - loss: 0.014383941888809204\n",
      "#4199 - loss: 2.1465327739715576\n",
      "#4399 - loss: 0.00016649177996441722\n"
     ]
    }
   ],
   "source": [
    "for (i, x_item) in enumerate(vocabProcessor.fit_transform(trainData['Content'])):\n",
    "    y_item = trainData.iloc[i]['Label']\n",
    "    feedDict = {X: x_item, y: [[y_item]]}\n",
    "    sess.run(train, feed_dict=feedDict)\n",
    "    \n",
    "    if (i + 1) % 200 == 0:\n",
    "        lossRes = sess.run(loss, feed_dict=feedDict)\n",
    "        print('#{0} - loss: {1}'.format(i, lossRes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#49 - accuracy: 0.88:\n",
      "#99 - accuracy: 0.84:\n",
      "#149 - accuracy: 0.82:\n",
      "#199 - accuracy: 0.83:\n",
      "#249 - accuracy: 0.824:\n",
      "#299 - accuracy: 0.82:\n",
      "#349 - accuracy: 0.8114285714285714:\n",
      "#399 - accuracy: 0.81:\n",
      "#449 - accuracy: 0.8111111111111111:\n",
      "#499 - accuracy: 0.81:\n",
      "#549 - accuracy: 0.8127272727272727:\n",
      "#599 - accuracy: 0.8116666666666666:\n",
      "#649 - accuracy: 0.8215384615384616:\n",
      "#699 - accuracy: 0.83:\n",
      "#749 - accuracy: 0.8333333333333334:\n",
      "#799 - accuracy: 0.8275:\n",
      "#849 - accuracy: 0.8235294117647058:\n",
      "#899 - accuracy: 0.8244444444444444:\n",
      "#949 - accuracy: 0.8252631578947368:\n",
      "#999 - accuracy: 0.826:\n",
      "#1049 - accuracy: 0.8266666666666667:\n",
      "#1099 - accuracy: 0.8263636363636364:\n",
      "Overall Test Accuracy: 0.8269058295964126\n"
     ]
    }
   ],
   "source": [
    "testAccuracy = []\n",
    "\n",
    "for (i, x_item) in enumerate(vocabProcessor.fit_transform(testData['Content'])):\n",
    "    y_item = testData.iloc[i]['Label']\n",
    "    feedDict = {X: x_item, y: [[y_item]]}\n",
    "    predictionRes = sess.run(prediction, feed_dict=feedDict)\n",
    "    testAccuracy.append(y_item == np.round(predictionRes))\n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        print('#{0} - accuracy: {1}:'.format(i, np.mean(testAccuracy)))\n",
    "\n",
    "print('Overall Test Accuracy: {0}'.format(np.mean(testAccuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
