{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from SpamData import SpamData\n",
    "from Partition import partition_indices\n",
    "%matplotlib inline\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamData = SpamData()\n",
    "spamDf = spamData.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i dont think goes usf lives around though</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                            Content  Label  Text Length\n",
       "0   ham  go jurong point crazy available bugis n great ...      0           16\n",
       "1   ham                            ok lar joking wif u oni      0            6\n",
       "2  spam  free entry wkly comp win fa cup final tkts st ...      1           20\n",
       "3   ham                u dun say early hor u c already say      0            9\n",
       "4   ham      nah i dont think goes usf lives around though      0            9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainIdx, testIdx = partition_indices(spamDf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = spamDf.iloc[trainIdx]\n",
    "print(trainData.shape)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = spamDf.iloc[testIdx]\n",
    "print(testData.shape)\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spamDf.hist('Text Length', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Identifying Embedding Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_SIZE = 35\n",
    "MIN_WORD_FREQ = 3\n",
    "\n",
    "vocabProcessor = learn.preprocessing.VocabularyProcessor(max_document_length=MAX_SENT_SIZE, min_frequency=MIN_WORD_FREQ)\n",
    "wordIdx = vocabProcessor.fit_transform(spamDf['Content'])\n",
    "embeddingSize = len(vocabProcessor.vocabulary_._mapping)\n",
    "print(type(wordIdx))\n",
    "embeddingSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**TEST**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = vocabProcessor.vocabulary_._mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(vocab))\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortedVocab = sorted(vocab.items(), key=lambda i: i[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedVocab[: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "list(itertools.islice(wordIdx, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingMx = tf.convert_to_tensor(np.eye(embeddingSize, dtype=np.float32))\n",
    "embeddingMx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring Parameters and Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal(shape=[embeddingSize, 1]), name='W')\n",
    "b = tf.Variable(tf.zeros(shape=[1, 1]), name='b')\n",
    "print(W)\n",
    "print(b)\n",
    "\n",
    "X = tf.placeholder(shape=[MAX_SENT_SIZE], dtype=tf.int32, name='X')\n",
    "y = tf.placeholder(shape=[1, 1], dtype=tf.float32, name='y')\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Indices of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embed = tf.nn.embedding_lookup(embeddingMx, X, name='X_embed')\n",
    "X_sums = tf.reduce_sum(X_embed, 0, name='X_sums')\n",
    "\n",
    "print(X_embed)\n",
    "print(X_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Outputs and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sums_2D = tf.expand_dims(X_sums, 0, name='X_sums_2D')\n",
    "output = tf.add(tf.matmul(X_sums_2D, W), b, name='output')\n",
    "print(X_sums_2D)\n",
    "print(output)\n",
    "\n",
    "prediction = tf.sigmoid(output, name='prediction')\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=output, name='loss'))\n",
    "print(prediction)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "train = optimizer.minimize(loss, name='train')\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, x_item) in enumerate(vocabProcessor.fit_transform(trainData['Content'])):\n",
    "    y_item = trainData.iloc[i]['Label']\n",
    "    feedDict = {X: x_item, y: [[y_item]]}\n",
    "    sess.run(train, feed_dict=feedDict)\n",
    "    \n",
    "    if (i + 1) % 200 == 0:\n",
    "        lossRes = sess.run(loss, feed_dict=feedDict)\n",
    "        print('#{0} - loss: {1}'.format(i, lossRes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAccuracy = []\n",
    "\n",
    "for (i, x_item) in enumerate(vocabProcessor.fit_transform(testData['Content'])):\n",
    "    y_item = testData.iloc[i]['Label']\n",
    "    feedDict = {X: x_item, y: [[y_item]]}\n",
    "    predictionRes = sess.run(prediction, feed_dict=feedDict)\n",
    "    testAccuracy.append(y_item == np.round(predictionRes))\n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        print('#{0} - accuracy: {1}:'.format(i, np.mean(testAccuracy)))\n",
    "\n",
    "print('Overall Test Accuracy: {0}'.format(np.mean(testAccuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
